## Laborat√≥rio de Fala ‚Äî Colab Sandbox

Este projeto √© um laborat√≥rio interativo de fala desenvolvido no Google Colab, que permite ao usu√°rio gravar sua voz, transcrever o √°udio, analisar o sentimento do texto e extrair palavras-chave ‚Äî tudo em uma interface web simples criada com Gradio.

Funcionalidades:

üéß Grava√ß√£o de √°udio direto pelo microfone.

üó£Ô∏è Transcri√ß√£o autom√°tica de fala com o modelo Whisper da OpenAI.

üí¨ An√°lise de sentimento multil√≠ngue utilizando o modelo nlptown/bert-base-multilingual-uncased-sentiment.

üè∑Ô∏è Extra√ß√£o de palavras-chave com o algoritmo YAKE (Yet Another Keyword Extractor).

üîä S√≠ntese de voz (Text-to-Speech) com gTTS, convertendo o texto transcrito novamente em √°udio.

üåê Interface web interativa constru√≠da com Gradio.

üß© Estrutura do Notebook:

O projeto √© dividido em 5 c√©lulas principais, descritas abaixo:

üß± C√©lula 1 ‚Äî Instala√ß√£o de Depend√™ncias

![Instala√ß√£o das Bibliotecas](images/install.png)


Instala os pacotes necess√°rios para o funcionamento do projeto:

```bash
!pip install -q --upgrade pip
!pip install -q git+https://github.com/openai/whisper.git     # Whisper (OpenAI)
!pip install -q gradio==3.39.0                                # Interface Web
!pip install -q transformers                                  # Modelos Hugging Face
!pip install -q yake                                          # Extra√ß√£o de keywords
!pip install -q gTTS                                          # Text-to-Speech
!pip install -q soundfile                                     # Manipula√ß√£o de √°udio
```

üß† C√©lula 2 ‚Äî Imports e Carregamento dos Modelos

![Carregamento dos Modelos](images/Carregamento_rapido.png)


Carrega as bibliotecas e inicializa os modelos principais:

Whisper (modelo small): utilizado para transcri√ß√£o de √°udio.

Pipeline de sentimento: modelo multil√≠ngue da Hugging Face.

YAKE: configura√ß√£o para extrair at√© 8 palavras-chave em portugu√™s.

‚öôÔ∏è C√©lula 3 ‚Äî Fun√ß√µes Utilit√°rias

![Fun√ß√µes Utilit√°rias](images/Fun√ß√£o_Utilit√°ria.png)


Cont√©m as fun√ß√µes principais do projeto:

transcribe_audio(): realiza a transcri√ß√£o de um arquivo de √°udio. 


analyze_sentiment(): analisa o sentimento do texto transcrito.


extract_keywords(): extrai as principais palavras-chave.


text_to_speech(): converte o texto em √°udio com voz sintetizada.


Exemplo de uso:
```python
texto = "A an√°lise de dados √© um processo sist√™mico para inspecionar, limpar, transformar e modelar dados brutos."
arquivo = text_to_speech(texto)
display(Audio(arquivo, autoplay=True))
```


üîó C√©lula 4 ‚Äî Fun√ß√£o Principal

![Fun√ß√£o Principal](images/Fun√ß√£o_Integra_Tudo.png)


Integra todas as fun√ß√µes anteriores para processar o √°udio completo:
```python
def process_audio(audio_file):
    transcript = transcribe_audio(audio_file)
    sentiment = analyze_sentiment(transcript)
    keywords = extract_keywords(transcript)
    tts_file = text_to_speech(transcript, lang="pt")
    return transcript, sentiment, keywords, tts_file
```
üñ•Ô∏è C√©lula 5 ‚Äî Interface com Gradio

![Interface Gradio](images/Interface_Gracio.png)


Cria a interface web que permite:

Gravar a fala do usu√°rio.

Exibir a transcri√ß√£o do √°udio.

Mostrar o resultado da an√°lise de sentimento.

Listar as palavras-chave detectadas.

Reproduzir o √°udio sintetizado.
```python
demo.launch(share=True) : gera um link p√∫blico tempor√°rio.
```
üß∞ Tecnologias Utilizadas:

| Biblioteca                | Fun√ß√£o Principal               |
|---------------------------|-------------------------------|
| Whisper                   | Transcri√ß√£o de fala           |
| Gradio                    | Interface interativa          |
| Transformers (Hugging Face)| An√°lise de sentimento        |
| YAKE                      | Extra√ß√£o de palavras-chave    |
| gTTS                      | S√≠ntese de fala               |
| SoundFile                 | Manipula√ß√£o de arquivos de √°udio |


![Laborat√≥rio de Fala](images/Laboratorio_de_Fala.png)


üß† Conceitos Envolvidos:

Processamento de √Åudio (ASR ‚Äî Automatic Speech Recognition)

An√°lise de Sentimento Multil√≠ngue

Extra√ß√£o de Informa√ß√£o (Keywords)

S√≠ntese de Voz (TTS)

Aplica√ß√µes Interativas de Machine Learning

üí° Como Executar:

Abra o notebook no Google Colab.

Execute todas as c√©lulas na ordem apresentada.

Aguarde o carregamento do link p√∫blico gerado pelo Gradio.

Grave sua fala, visualize a transcri√ß√£o e explore as an√°lises!

üì¶ Requisitos:

Conta Google (para usar o Colab).

Microfone funcional.

Conex√£o com a internet.

Python 3.10+ (no ambiente Colab).

üßæ Licen√ßa

Este projeto √© um prot√≥tipo educacional e livre para uso e modifica√ß√£o com fins de aprendizado.

‚ú® Autoria

[V√¢nia Cristina Bordin Freitas]

üí¨ Projeto criado para explorar modelos de linguagem, processamento de √°udio e interfaces interativas em Python.
