## LaboratÃ³rio de Fala â€” Colab Sandbox

Este projeto Ã© um laboratÃ³rio interativo de fala desenvolvido no Google Colab, que permite ao usuÃ¡rio gravar sua voz, transcrever o Ã¡udio, analisar o sentimento do texto e extrair palavras-chave â€” tudo em uma interface web simples criada com Gradio.

Funcionalidades:

ğŸ§ GravaÃ§Ã£o de Ã¡udio direto pelo microfone.

ğŸ—£ï¸ TranscriÃ§Ã£o automÃ¡tica de fala com o modelo Whisper da OpenAI.

ğŸ’¬ AnÃ¡lise de sentimento multilÃ­ngue utilizando o modelo nlptown/bert-base-multilingual-uncased-sentiment.

ğŸ·ï¸ ExtraÃ§Ã£o de palavras-chave com o algoritmo YAKE (Yet Another Keyword Extractor).

ğŸ”Š SÃ­ntese de voz (Text-to-Speech) com gTTS, convertendo o texto transcrito novamente em Ã¡udio.

ğŸŒ Interface web interativa construÃ­da com Gradio.

ğŸ§© Estrutura do Notebook:

O projeto Ã© dividido em 5 cÃ©lulas principais, descritas abaixo:

ğŸ§± CÃ©lula 1 â€” InstalaÃ§Ã£o de DependÃªncias
![InstalaÃ§Ã£o das Bibliotecas](images/install.png)


Instala os pacotes necessÃ¡rios para o funcionamento do projeto:

!pip install -q --upgrade pip
!pip install -q git+https://github.com/openai/whisper.git   # Whisper (OpenAI)
!pip install -q gradio==3.39.0                              # Interface Web
!pip install -q transformers                                # Modelos Hugging Face
!pip install -q yake                                        # ExtraÃ§Ã£o de keywords
!pip install -q gTTS                                        # Text-to-Speech
!pip install -q soundfile                                   # ManipulaÃ§Ã£o de Ã¡udio

ğŸ§  CÃ©lula 2 â€” Imports e Carregamento dos Modelos
![Carregamento dos Modelos](images/Carregamento_rapido.png)
Carrega as bibliotecas e inicializa os modelos principais:

Whisper (modelo small): utilizado para transcriÃ§Ã£o de Ã¡udio.

Pipeline de sentimento: modelo multilÃ­ngue da Hugging Face.

YAKE: configuraÃ§Ã£o para extrair atÃ© 8 palavras-chave em portuguÃªs.

âš™ï¸ CÃ©lula 3 â€” FunÃ§Ãµes UtilitÃ¡rias
![FunÃ§Ãµes UtilitÃ¡rias](images/FunÃ§Ã£o_UtilitÃ¡ria.png)
ContÃ©m as funÃ§Ãµes principais do projeto:

transcribe_audio(): realiza a transcriÃ§Ã£o de um arquivo de Ã¡udio.

analyze_sentiment(): analisa o sentimento do texto transcrito.

extract_keywords(): extrai as principais palavras-chave.

text_to_speech(): converte o texto em Ã¡udio com voz sintetizada.

Exemplo de uso:

texto = "A anÃ¡lise de dados Ã© um processo sistÃªmico para inspecionar, limpar, transformar e modelar dados brutos."
arquivo = text_to_speech(texto)
display(Audio(arquivo, autoplay=True))

ğŸ”— CÃ©lula 4 â€” FunÃ§Ã£o Principal
![FunÃ§Ã£o Principal](images/FunÃ§Ã£o_Integra_Tudo.png)
Integra todas as funÃ§Ãµes anteriores para processar o Ã¡udio completo:

def process_audio(audio_file):
    transcript = transcribe_audio(audio_file)
    sentiment = analyze_sentiment(transcript)
    keywords = extract_keywords(transcript)
    tts_file = text_to_speech(transcript, lang="pt")
    return transcript, sentiment, keywords, tts_file

ğŸ–¥ï¸ CÃ©lula 5 â€” Interface com Gradio
![Interface Gradio](images/Interface_Gracio.png)
Cria a interface web que permite:

Gravar a fala do usuÃ¡rio.

Exibir a transcriÃ§Ã£o do Ã¡udio.

Mostrar o resultado da anÃ¡lise de sentimento.

Listar as palavras-chave detectadas.

Reproduzir o Ã¡udio sintetizado.

demo.launch(share=True) : gera um link pÃºblico temporÃ¡rio.

ğŸ§° Tecnologias Utilizadas
Biblioteca | FunÃ§Ã£o Principal
Whisper |	TranscriÃ§Ã£o de fala
Gradio |	Interface interativa
Transformers (Hugging Face)	| AnÃ¡lise de sentimento
YAKE |	ExtraÃ§Ã£o de palavras-chave
gTTS |	SÃ­ntese de fala
SoundFile |	ManipulaÃ§Ã£o de arquivos de Ã¡udio

![LaboratÃ³rio de Fala](images/Laboratorio_de_Fala.png)
ğŸ§  Conceitos Envolvidos:

Processamento de Ãudio (ASR â€” Automatic Speech Recognition)

AnÃ¡lise de Sentimento MultilÃ­ngue

ExtraÃ§Ã£o de InformaÃ§Ã£o (Keywords)

SÃ­ntese de Voz (TTS)

AplicaÃ§Ãµes Interativas de Machine Learning

ğŸ’¡ Como Executar:

Abra o notebook no Google Colab.

Execute todas as cÃ©lulas na ordem apresentada.

Aguarde o carregamento do link pÃºblico gerado pelo Gradio.

Grave sua fala, visualize a transcriÃ§Ã£o e explore as anÃ¡lises!

ğŸ“¦ Requisitos:

Conta Google (para usar o Colab).

Microfone funcional.

ConexÃ£o com a internet.

Python 3.10+ (no ambiente Colab).

ğŸ§¾ LicenÃ§a

Este projeto Ã© um protÃ³tipo educacional e livre para uso e modificaÃ§Ã£o com fins de aprendizado.

âœ¨ Autoria

Autora: [VÃ¢nia Cristina Bordin Freitas]
ğŸ’¬ Projeto criado para explorar modelos de linguagem, processamento de Ã¡udio e interfaces interativas em Python.
